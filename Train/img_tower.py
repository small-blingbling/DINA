import torch
import torch.nn as nn
import torch.nn.functional as F

from models import ds_net_small   # ğŸ”¥ è°ƒç”¨ä½ ä¿®å¤åçš„ DS-Net small


class DSNetSingleStage(nn.Module):
    def __init__(self, stage=2, block=4):
        super().__init__()
        self.stage = stage
        self.block = block

        self.base = ds_net_small(img_size=68, num_classes=0, in_chans=1)

        # æ³¨å†Œ hook
        self._register_target_hook()

        # ä¿å­˜ hook ç‰¹å¾
        self.features = {}

        self.my_conv = nn.Conv2d(128, 1, kernel_size=1)


    def _register_target_hook(self):
        target_name = f"blocks{self.stage}.{self.block - 1}"
        print(f"âœ… Hook æ³¨å†Œåˆ°: {target_name}")

        module_dict = dict(self.base.named_modules())
        assert target_name in module_dict, f"âŒ æœªæ‰¾åˆ°æ¨¡å— {target_name}"

        def hook_fn(module, input, output):
            self.features["feat"] = output.detach()

        module_dict[target_name].register_forward_hook(hook_fn)


    def forward(self, x):

        self.features.clear()

        _ = self.base(x)

        assert "feat" in self.features, "âŒ Hook æœªè§¦å‘ï¼ˆæ£€æŸ¥ stage å’Œ block æ˜¯å¦åŒ¹é…ï¼‰"

        feat = self.features["feat"]

        # 320-ch â†’ 1-ch
        feat = self.my_conv(feat)

        # ä¸Šé‡‡æ ·æˆ 32Ã—32
        feat = F.interpolate(feat, size=(16, 64), mode="bilinear")

        # å½’ä¸€åŒ–
        feat_min = feat.amin(dim=(2, 3), keepdim=True)
        feat_max = feat.amax(dim=(2, 3), keepdim=True)
        feat = (feat - feat_min) / (feat_max - feat_min + 1e-8)

        return feat



# =============================
# ğŸ” æµ‹è¯•
# =============================
if __name__ == "__main__":
    model = DSNetSingleStage(stage=3, block=9)  # ğŸ”¥ æŒ‡å®šä½¿ç”¨ blocks3[7]
    model.eval()

    x = torch.randn(10, 1, 68, 270)  # è¾“å…¥å•é€šé“è‡ªç„¶å›¾
    out = model(x)
    print("è¾“å‡ºç»“æœ:", out.shape)
